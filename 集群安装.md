# 集群安装
## 准备：
* 安装JDK（不是本章重点，自行安装接口）
* 关闭防火墙
```
systemctl stop firewalld.service
systemctl disable firewalld.service
```
* 3. 在每个服务器的/etc/hosts中配置集群所有服务器的host和ip
* 4. 配置ssh免密登录
```
cd /root/.ssh
ssh-keygen -t rsa          #一直回车就行
ssh-copy-id root@test01   #将公钥拷贝到其他服务器，需要root登录密码
```
## 1. 下载Kafka
官网下载地址首页：http://kafka.apache.org/downloads.html
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kafka-install-1.jpg)
* 我们下载kafka_2.13-2.6.0.tgz，点击跳转：https://www.apache.org/dyn/closer.cgi?path=/kafka/2.6.0/kafka_2.13-2.6.0.tgz
```shell
wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.6.0/kafka_2.13-2.6.0.tgz
```
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kafka-install-2.jpg)

## 2. 安装
### 2.1 解压kafka
```
tar -xzvf kafka_2.13-2.6.0.tgz 
```
### 2.2 Zookerper安装
#### 2.2.1 Zookeeper配置
本文使用其自带的Zookeeper建立集群  
* Kafka自带的Zookeeper程序使用bin/zookeeper-server-start.sh，以及bin/zookeeper-server-stop.sh来启动和停止Zookeeper。
* Kafka的Zookeeper的配制文件是config/zookeeper.properties，不是zoo.cfg
* 配置：
```
#计时周期时间，zookeeper中使用的基本时间单位, 毫秒值.
tickTime=2000
#同步限制，该参数配置leader和follower之间发送消息, 请求和应答的最大时间长度. 此时该参数设置为5, 说明时间限制为5倍tickTime, 即10000ms.
syncLimit=5
#初始化限制，zookeeper集群中的包含多台server, 其中一台为leader, 集群中其余的server为follower。 initLimit参数配置初始化连接时, follower和leader之间的最长心跳时间. 此时该参数设置为10, 说明时间限制为5倍tickTime, 即10*2000=20000ms=20s.
initLimit=10
#最大客户端连接数
maxClientCnxns=1000
#最小会话超时
minSessionTimeout=4000
#最大会话超时
maxSessionTimeout=60000
#存储快照文件的目录
dataDir=/data/zk/data
#默认情况下， 事务日志也会存储在该目dataDir录上。由于事务日志 的写性能直接影响 ZooKeeper 性能，因此 建议同时配置参数 dataLogDir
dataLogDir=/data/zk/logs
# 客户端端口
clientPort=2181
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
# admin.serverPort=8080
#端口号2888表示该服务器与集群中leader交换信息的端口，默认为2888， 3888表示选举时服务器相互通信的端口
#server.X=A:B:C 其中X是一个数字, 表示这是第几号server. A是该server所在的IP地址. B配置该server和集群中的leader交换消息所使用的端口. C配置选举leader时所使用的端口. 由于配置的是伪集群模式, #所以各个server的B, C参数必须不同
server.1=test01:2888:3888
server.2=test02:2888:3888
server.3=test03:2888:3888
```
* 创建myid文件：在${dataDir}路径下创建一个myid文件，myid中只用存放的值就是服务器的编号（例如server.1对应的服务器的myid中的值是1）。ZooKeeper在启动时会读取 myid文件 中的值与 zoo.cfg文件中的配置信息进行比较，以确定是哪台服务器。
#### 2.2.2 Zookeeper启动
```
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```
查看日志
```
cat logs/zookeeper.out
```
#### 2.2.3 Zookeeper状态查询
```
bin/kafka-run-class.sh org.apache.zookeeper.client.FourLetterWordMain localhost 2181 srvr
```
* localhost：zookeeper的地址。
* 2181：zookeeper监听端口
执行结果：
```
Zookeeper version: 3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT
Latency min/avg/max: 0/0/0
Received: 1
Sent: 0
Connections: 1
Outstanding: 0
Zxid: 0x200000004
Mode: follower
Node count: 5
```
* Mode：follower显示为从节点，leader为主节点
#### 2.2.4 启动Zookeeper的shell
```
bin/zookeeper-shell.sh localhost:2181
```
* localhost：zookeeper的地址。
* 2181：zookeeper监听端口
#### 2.2.4 关闭Zookeeper
```
bin/zookeeper-server-stop.sh -daemon config/zookeeper.properties
```
### 2.3 Kafka安装
#### 2.3.1 配置kafka
```properties
#在执行第一次再平衡之前，group协调员将等待更多消费者加入group的时间。 延迟时间越长意味着重新平衡的可能性越小，但是等待处理开始的时间增加
group.initial.rebalance.delay.ms=0
#broker.id是kafka broker的编号，集群里每个broker的id需不同,只要保证不同，可以为任意数字
broker.id=1
#listeners是监听地址，需要提供外网服务的话，要设置本地的IP地址
listeners=PLAINTEXT://test01:9092
#kafka数据存储目录
log.dirs=/data/kafka/data
#设置Zookeeper集群地址
zookeeper.connect=vms-zhkafka01:2181,vms-zhkafka02:2181,vms-zhkafka03:2181
#为新建Topic的默认Partition数量
num.partitions=1
#follow从leader拉取消息进行同步数据的拉取线程数
num.replica.fetchers=1
#kafka日志存放路径
kafka.log4j.dir=/data/log/kafka
#是否自动创建topic，当读写数据时，如果topic没有则会自动创建
auto.create.topics.enable=true
#启用自动均衡
auto.leader.rebalance.enable=true
#broker在关闭时会向controller报告自己关闭，这样controller可以对broker的下线及时做一些操作，比如partition的重新选举、分区副本的关闭、通知其他的broker元数据变动等
controlled.shutdown.enable=true
#broker关闭时向contoller发送报告的重试次数
controlled.shutdown.max.retries=3
#ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大
zookeeper.session.timeout.ms=6000
#ZooKeeper的连接超时时间
zookeeper.connection.timeout.ms =18000
#topic默认分区的replication个数 ，不能大于集群中broker的个数。
default.replication.factor=2
#broker处理消息的最大线程数，一般情况下不需要去修改,默认3
num.network.threads=3
#broker处理磁盘IO的线程数，数值应该大于你的硬盘数
num.io.threads=8
#socket的发送缓冲区，socket的调优参数SO_SNDBUFF
socket.send.buffer.bytes=102400
#socket的接受缓冲区，socket的调优参数SO_RCVBUFF
socket.receive.buffer.bytes=102400
#socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖
socket.request.max.bytes=104857600
#broker启动的过程中会加载此节点上所有topic的log文件，如果数据量非常大会导致加载时间过长，通过修改处理线程数可以加快log的恢复速度。默认1
num.recovery.threads.per.data.dir=1
# topic的offset的备份份数（消费者offset）。建议设置更高的数字保证更高的可用性
offsets.topic.replication.factor=3
#事务日志Topic副本数
transaction.state.log.replication.factor=3
#指定事务日志Topic的ISR中的最小副本数是多少，用于服务min.insync.replicas，默认值为1
transaction.state.log.min.isr=2
#启用删除主题。 如果此配置已关闭，则通过管理工具删除主题将不起作用。删除topic是影响注册在/admin/delete_topics的监听
delete.topic.enable=true
#日志达到删除大小的阈值,-1为不限制
log.retention.bytes=-1
#检查日志段文件的间隔时间，以确定是否文件属性是否到达删除要求
log.retention.check.interval.ms=300000
#每个日志文件删除之前保存的时间，单位小时
log.retention.hours=12
#topic 分区的日志存放在某个目录下诸多文件中，这些文件将partition的日志切分成一段一段的，这就是段文件（segment file）；一个topic的一个分区对应的所有segment文件称为log。这个设置控制着一个segment文件的最大的大小，如果超过了此大小，就会生成一个新的segment文件
log.segment.bytes=1073741824
#这个设置会强制Kafka去新建一个新的log segment文件，即使当前使用的segment文件的大小还没有超过log.segment.bytes
log.roll.hours=168
#分区rebalance检查的频率，由控制器触发,默认300
leader.imbalance.check.interval.seconds=300
#每个broker允许的不平衡的leader的百分比。如果每个broker超过了这个百分比，复制控制器会对分区进行重新的平衡。该值以百分比形式指定，默认10
leader.imbalance.per.broker.percentage=10
#日志压缩去重时候的缓存空间，在空间允许的情况下，越大越好，默认134217728
log.cleaner.dedupe.buffer.size=134217728
#对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据，默认86400000
log.cleaner.delete.retention.ms=86400000
#启用日志清理器进程在服务器上运行。使用了cleanup.policy = compact的主题，包括内部offsets主题，都应该启动该选项。如果被禁用的话，这些话题将不会被压缩，并且会不断增长，默认true
log.cleaner.enable=true
#控制了log compactor进行clean操作的频率。默认情况下，当log的50%以上已被clean时，就不用继续clean了。此配置可以被覆盖。默认0.5
log.cleaner.min.cleanable.ratio=0.5
#用于日志清理的后台线程的数量，默认1
log.cleaner.threads=1
#kafka允许的最大的一个批次的消息大小。 如果这个数字增加，并且有0.10.2版本以下的消费者，那么消费者的提取大小也必须增加，以便他们可以取得这么大的记录批次。在最新的消息格式版本中，记录总是被组合到一个批次以提高效率。 在以前的消息格式版本中，未压缩的记录不会分组到批次中，并且此限制仅适用于该情况下的单个记录。可以使用主题级别max.message.bytes来设置每个主题，默认1000012
message.max.bytes=1000000
#当生产者将ack设置为“全部”（或“-1”）时，min.insync.replicas指定必须确认写入被认为成功的最小副本数（必须确认每一个repica的写数据都是成功的）。 如果这个最小值不能满足，那么生产者将会引发一个异常（NotEnoughReplicas或NotEnoughReplicasAfterAppend）。当一起使用时，min.insync.replicas和acks允许您强制更大的耐久性保证。 一个典型的情况是创建一个复制因子为3的主题，将min.insync.replicas设置为2，并且生产者使用“all”选项。 这将确保如果大多数副本没有写入生产者则抛出异常。默认1
min.insync.replicas=1
#erver端处理请求时的I/O线程的数量，不要小于磁盘的数量。默认8
num.io.threads=8
#Offsets topic的分区数量（部署后不应更改），默认50
offsets.topic.num.partitions=50
#仅在未设置“listeners”时使用。 使用listeners来代替。 这个端口来监听和接受连接
#port=9092
#为每个分区设置获取的消息的字节数。 这不是绝对最大值，如果第一个非空分区中的第一个record batch大于此值，那么record batch仍将被返回以确保可以进行。 代理接受的最大记录批量大小通过message.max.bytes（broker config）或max.message.bytes（topic config）进行定义，默认1048576
replica.fetch.max.bytes=1048576
#如果一个follower在这个时间内没有发送fetch请求，leader将从ISR重移除这个follower，并认为这个follower已经挂了,默认10000
replica.lag.time.max.ms=10000
#指明了是否能够使不在ISR中replicas follower设置用来作为leader,默认aflse
unclean.leader.election.enable=false
#用于经纪人之间沟通的监听协议
security.inter.broker.protocol=PLAINTEXT
#服务器是否允许自动生成broker.id；如果允许则产生的值会交由reserved.broker.max.id审核，默认false
broker.id.generation.enable=false
```
#### 2.3.2 启动kafka
```
#-daemon 参数会将任务转入后台运行，输出日志信息将写入日志文件，日志文件在执行命令的目录下的logs目录中kafkaServer.out，结尾输同started说明启动成功
bin/kafka-server-start.sh -daemon config/server.properties
```
* 查看日志
```
cat logs/kafkaServer.out
```
* 停止kafka
```
bin/kafka-server-stop.sh -daemon config/server.properties
```
#### 2.3.3 测试
* 创建Topic
```
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic myTest
```
执行结果
```
[root@test01 kafka_2.13-2.6.0]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic myTest
Created topic myTest.
```
* 查看Topic
```
bin/kafka-topics.sh --list --zookeeper localhost:2181
```
执行结果
```
root@vms-zhkafka03 kafka_2.13-2.6.0]# bin/kafka-topics.sh --list --zookeeper localhost:2181
myTest
```

* 发送消息

* 接收消息

* 查看特定主题的详细信息

* 删除主题












