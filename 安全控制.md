# kafka安全控制
# 一、使用SSL管理通讯安全
## 1.创建所需ssl证书文件
### 脚本
```shell
#!/bin/bash
#################################
BASE_DIR=/data/kafka-ssl
CERT_OUTPUT_PATH="$BASE_DIR/server_cert"
CLIENT_CERT_OUTPUT_PATH="$BASE_DIR/client_cert"
PASSWORD=123456
KEY_STORE="$CERT_OUTPUT_PATH/kafka.keystore.jks"
CLIENT_KEY_STORE="$CLIENT_CERT_OUTPUT_PATH/client-keystore.jks"
TRUST_STORE="$CERT_OUTPUT_PATH/kafka.truststore.jks"
CLIENT_TRUST_STORE="$CLIENT_CERT_OUTPUT_PATH/client-truststore.jks"
CLUSTER_NAME=test
CERT_AUTH_FILE="$CERT_OUTPUT_PATH/ca.crt"
CLUSTER_CERT_FILE="$CERT_OUTPUT_PATH/${CLUSTER_NAME}-cert"
CLIENT_CLUSTER_CERT_FILE="$CERT_OUTPUT_PATH/${CLUSTER_NAME}-cert-client"
DAYS_VALID=999
DNAME="CN=test,OU=test,O=test,L=test,ST=test,C=CN"
#################################
mkdir -p $CERT_OUTPUT_PATH
mkdir -p $CLIENT_CERT_OUTPUT_PATH

echo "1:创建服务端秘钥和证书"
keytool -keystore $KEY_STORE -alias $CLUSTER_NAME -validity $DAYS_VALID -genkey -keyalg RSA \
-storepass $PASSWORD -keypass $PASSWORD -dname "$DNAME"

echo "2:创建客户端秘钥和证书"
keytool -keystore $CLIENT_KEY_STORE -alias $CLUSTER_NAME -validity $DAYS_VALID -genkey -keyalg RSA \
-storepass $PASSWORD -keypass $PASSWORD -dname "$DNAME"

echo "3:创建CA证书"
openssl req -new -x509 -keyout $CERT_OUTPUT_PATH/ca.key -out "$CERT_AUTH_FILE" -days "$DAYS_VALID" \
-passin pass:"$PASSWORD" -passout pass:"$PASSWORD" \
-subj "/C=CN/ST=test/L=test/O=test/CN=CN"

echo "4:将CA证书导入到服务器truststore"
keytool -keystore "$TRUST_STORE" -alias CARoot \
-import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "5:将CA证书导入到客户端truststore"
keytool -keystore "$CLIENT_TRUST_STORE" -alias CARoot \
-import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "6.导出服务器证书"
keytool -keystore "$KEY_STORE" -alias "$CLUSTER_NAME" -certreq -file "$CLUSTER_CERT_FILE" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "7.导出客户器证书"
keytool -keystore "$CLIENT_KEY_STORE" -alias "$CLUSTER_NAME" -certreq -file "$CLIENT_CLUSTER_CERT_FILE" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "8.用CA证书给服务器证书签名"
openssl x509 -req -CA "$CERT_AUTH_FILE" -CAkey $CERT_OUTPUT_PATH/ca.key -in "$CLUSTER_CERT_FILE" \
-out "${CLUSTER_CERT_FILE}-signed" \
-days "$DAYS_VALID" -CAcreateserial -passin pass:"$PASSWORD"

echo "8.用CA证书给客户器证书签名"
openssl x509 -req -CA "$CERT_AUTH_FILE" -CAkey $CERT_OUTPUT_PATH/ca.key -in "$CLIENT_CLUSTER_CERT_FILE" \
-out "${CLIENT_CLUSTER_CERT_FILE}-signed" \
-days "$DAYS_VALID" -CAcreateserial -passin pass:"$PASSWORD"
 
echo "9.将CA证书导入服务端keystore"
keytool -keystore "$KEY_STORE" -alias CARoot -import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "10.将CA证书导入客户端keystore"
keytool -keystore "$CLIENT_KEY_STORE" -alias CARoot -import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "11:将已签名的服务端证书导入服务器keystore"
keytool -keystore "$KEY_STORE" -alias "${CLUSTER_NAME}" -import -file "${CLUSTER_CERT_FILE}-signed" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "11:将已签名的客户端证书导入服务器keystore"
keytool -keystore "$CLIENT_KEY_STORE" -alias "${CLUSTER_NAME}" -import -file "${CLIENT_CLUSTER_CERT_FILE}-signed" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt
```
创建的文件清单：
* 服务端文件
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-1.jpg)
* 客户端文件
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-2.jpg)

## 2.服务端配置
### 2.1 配置ssl监听
Kafka Broker支持监听多个端口上的连接，通过server.properteis 配置，最少监听1个端口，用逗号分隔。
```
listeners=PLAINTEXT://host.name:port,SSL://host.name:port
```
* CDH对应配置
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-3.png)
### 2.2 配置ssl文件和密码
```
ssl.keystore.location=/data/kafka-ssl/server_cert/kafka.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/data/kafka-ssl/server_cert/kafka.truststore.jks
ssl.truststore.password=test1234
```
* CDH对应配置
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-4.png)
### 2.2 ssl其他配置
### 2.2.1 ssl.client.auth
* required：客户端身份验证是必需的，客户端必须同时配置keystore和truststore
* node：不启动验证
* requested：客户端身份验证请求，客户端没有证书仍然可以连接，客户端连接Kafka只用配置truststore
* CDH配置：
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-5.png)
### 2.2.2. ssl.enabled.protocols = TLSv1.2 TLSv1.1 TLSv1 
* TLSv1.2 TLSv1.1 TLSv1 ，接收来自客户端列出的SSL协议，注意，不推荐在生产中使用SSL，推荐使用TLS)。
* CDH不能配置具体协议，只能选择是否启动
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-6.png)
### 2.2.3. security.inter.broker.protocol 
* broker内部通信使用协议，默认和外部通讯协议保持一致，在CDH中需要也配置成SSL，普通kafka根据实际情况配置，一版配置为普通文本模式，不用
 ![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-7.jpg)
 ### 2.2.4. 其他
* ssl.keystore.type=JKS
* ssl.truststore.type=JKS
* ssl.secure.random.implementation=SHA1PRNG
* advertised.listeners = SSL://localhost:9095
* advertised.listeners和listeners的区别：
   listeners：就是主要用来定义Kafka Broker的Listener的配置项。
   advertised.listeners：参数的作用就是将Broker的Listener信息发布到Zookeeper中，也就是说通过zk链接kafka里的broker是这个配置的对应监听地址，如果advertised.listeners未配置，会使用listeners的值
### 配置案例
```
listeners=SSL://localhost:9095
advertised.listeners=SSL://localhost:9095
ssl.keystore.location=/Users/smartloli/workspace/ssl/certificates/kafka.keystore
ssl.keystore.password=ke123456
ssl.key.password=ke123456
ssl.truststore.location=/Users/dengjie/workspace/ssl/certificates/kafka.truststore
ssl.truststore.password=ke123456

ssl.client.auth=required
ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1
ssl.keystore.type=JKS 
ssl.truststore.type=JKS 
ssl.endpoint.identification.algorithm=HTTPS
security.inter.broker.protocol=SSL
```
## 3.客户端配置
```
#broker的ip端口，逗号分隔多个
bootstrap.servers=localhost:9095
#加密协议方式
security.protocol=SSL
#keystore地址
ssl.keystore.location=/Users/smartloli/workspace/ssl/certificates/kafka.keystore
#keystore密码
ssl.keystore.password=ke123456
#key密码
ssl.key.password=ke123456
#truststore文件地址
ssl.truststore.location=/Users/dengjie/workspace/ssl/certificates/kafka.truststore
#truststore密码
ssl.truststore.password=ke123456
```
## 4.SpringBoot Kafka 配置SSL
* 添加ssl相关配置
```yaml
# ssl基础配合配置
spring:
  kafka:
    producer: 
      properties:
        linger.ms: 0
        security:
          protocol: SSL
    consumer:
      properties:
        security:
          protocol: SSL
    ssl:
      key-store-location: file:C:/client-keystore.jks
      key-store-password: 123456
      key-password: 123456
      trust-store-location: file:C:/client-truststore.jks
      trust-store-password: 123456
      key-store-type: JKS
      trust-store-type: JKS
```
说明：就是在consumer、producer或者直接在kafka下的properties中配置kafka配置，配置的key值和kafka原生的一样
## 5.SpringCloudStream Kafka 配置SSL
```yaml
spring:
  cloud:
    stream:
      binders:
        kafka:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      brokers: test01:9093,test02:9093,test03:9093
                      configuration:
                        max:
                          poll:
                            interval:
                              ms: 60000
                        security:
                          protocol: SASL_SSL
                        ssl:
                          truststore:
                            type: JKS
                            location: C:/client-truststore.jks
                            password: 123456
                          keystore:
                            type: JKS
                            location: C:/client-truststore.jks
                            password: 123456
                          key:
                            password: 123456
                          client:
                            auth: required
```
说明：将配置放到configuration下
# 二、使用SASL对用户进行登录访问控制(不使用Kerberos)
注意：CDH只支持Kerberos，否则启动kafka会直接提示
```
security.inter.broker.protocol can not be set to SASL_SSL, as Kerberos is not enabled on this Kafka broker.
```
## 2.1 配置SASL
* 1.在broker中选择1个或多个支持的机制启用，kafka目前支持的机制有 GSSAPI 和 PLAIN 。  
* 2.在server.properties配置一个SASL端口，增加至少1个SASL_PLAINTEXT或SASL_SSL到listeners。用逗号分隔：
```
 listeners=SASL_PLAINTEXT://host.name:port
```
如果使用SASL_SSL，那SSL也必须配置，如果你仅配置SASL端口（或者，如果你需要broker互相使用SASL进行身份验证），那么，确保你设置相同的SASL协议为broker间通讯:
```
security.inter.broker.protocol=SASL_PLAINTEXT (or SASL_SSL)
```
* 3.在server.properties中启用1个或多个SASL机制:
```
sasl.enabled.mechanisms=GSSAPI (,PLAIN)
```
注意这里配置PLAIN,如果配置GSSAPI则需要安装Kerberos
* 4.如果使用SASL做broker之间通信，在server.properties中配置SASL机制：
```
sasl.mechanism.inter.broker.protocol=GSSAPI (or PLAIN)
```
注意这里配置PLAIN,如果配置GSSAPI则需要安装Kerberos
* 5.allow.everyone.if.no.acl.found=ture
该配置的意思是：如果用户没有配置任何acl权限，能否访问数据，默认是false，也就是除了超级用户之外，其他用户无法访问。  
那么问题就来了，在kafka集群中，其它节点需要同步数据，需要相互访问。节点之间是默认会使用ANONYMOUS的用户名连接集群。在这种情况下，启动kafka集群，必然失败！所以必须设置为true，然后给非超级用户严格控制访问权限
```
org.apache.kafka.common.errors.ClusterAuthorizationException: Request Request(processor=0, connectionId=10.88.25.65:9092-10.88.25.65:49446-0, session=Session(User:ANONYMOUS,/10.88.25.65), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=null) is not authorized.
```

* 6.配置实例：
```
# 配置ACL入口类
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
advertised.listeners=SASL_PLAINTEXT://$advertised_hostname:9092
# 本例使用SASL_PLAINTEXT
listeners=SASL_PLAINTEXT://:9092
security.inter.broker.protocol= SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN
allow.everyone.if.no.acl.found=true
# 设置本例中admin为超级用户
super.users=User:admin
```
## 2.1 启动服务端
### 2.1.1 为所有Kafka的Broker都添加一个JAAS文件来配置选择的 GSSAPI（Kerberos）或 PLANIN。  
本例中，我们假设有3个用户：admin, reader和writer，其中admin是管理员，reader用户读取Kafka集群中topic数据，而writer用户则负责向Kafka集群写入消息,存放目录：/data/kafka-conf/kafka_cluster_jaas.conf
```
KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="admin"
  password="123456"
  user_admin="123456"
  user_writer="writer123456"
  user_reader="reader123456"; 
};

```
这个文件，是专门用来做认证的。用户名和密码的式如下：user_用户名="密码"  
注意：这几行是固定的,这里是指当前服务作为客户端时方位kafka使用的账号和密码，注意这个账号密码必须要在【user_用户名="密码"】 中存在
```
username="admin"
password="123456"
```
### 2.1.3 启动Zookeeper
先来看一下，默认的bin/zookeeper-server-start.sh的最后一行
```
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain "$@"
```
修改脚本：  
* 由于kakfa的zk启动脚本，也会在java启动命令后面加上KAFKA_OPTS环境变量
* 而我们在启动kafka时export了这个变量,也就是只要kakfa启动过一次后系统中就export了KAFKA_OPTS
* 这将导致重启zk时会加载这个参数，而这个参数一旦加载，会让zk也启动alc机制，导致zk需要权限才能访问
```
unset KAFKA_OPTS
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS org.apache.zookeeper.server.quorum.QuorumPeerMain "$@"
```
启动
```
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```
### 2.1.4 启动Kafka
bin/kafka-server-start.sh 这个是kafka的启动脚本，要使用ACL，需要增加一个参数才行
有2种方法修改，这里分别介绍一下：
* 增加环境变量KAFKA_OPTS(在启动kafka自带的zk时也会默认加载这个变量，导致zk也启动了权限控制，直接访问都没有权限)
先来看一下，默认的bin/kafka-server-start.sh的最后一行
```
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```
只需要在最后一行的上面一行，添加一个环境变量即可
```
export KAFKA_OPTS="-Djava.security.auth.login.config=/data/kafka-conf/kafka_cluster_jaas.conf"
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```
* 增加参数-Djava.security.auth.login.config
直接将最后一行修改为
```
exec $base_dir/kafka-run-class.sh -Djava.security.auth.login.config=/data/kafka-conf/kafka_cluster_jaas.conf $EXTRA_ARGS kafka.Kafka "$@"
```
启动
```
bin/kafka-server-start.sh -daemon config/server.properties
```
* 说明：在启动sasl后，如果还有客户端通过非sasl连接kafka（listeners同时配置了sasl和plain的端口），kafka的日志里会出现如下提示，这是正常的
```
Failed authentication with 2.0.1.5/2.0.1.5 (Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
```
## 3.客户端配置
### 3.1 配置
* 配置JAAS文件,设置访问kafka的账号
```
KafkaClient{
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="test"
  password="test123456";
};
```
然后将JAAS配置文件位置作为JVM参数传递给每个Kafka代理
```
-Djava.security.auth.login.config = /etc/kafka/kafka_client_jaas.conf
```
* 在 producer.properties 或 consumer.properties 配置以下属性
```
 security.protocol=SASL_PLAINTEXT (or SASL_SSL)
 sasl.mechanism=PLAIN (or GSSAPI)
```
### 3.3 kafka-console-producer.sh配置
* 配置JAAS文件,设置访问kafka的账号
* 然后将JAAS配置文件位置作为JVM参数传递给每个Kafka代理
* vi bin/kafka-console-producer.sh,也就是添加KAFKA_OPTS
```shell
export KAFKA_OPTS="-Djava.security.auth.login.config=/etc/kafka/kafka_client_jaas.conf"
exec $(dirname $0)/kafka-run-class.sh kafka.tools.ConsoleProducer "$@"
```
* 修改生产者配置文件，最后一行追加2行内容
```shell
 security.protocol=SASL_PLAINTEXT (or SASL_SSL)
 sasl.mechanism=PLAIN (or GSSAPI)
```
### 3.4 kafka-console-consumer.sh配置
* 配置JAAS文件,设置访问kafka的账号
* 然后将JAAS配置文件位置作为JVM参数传递给每个Kafka代理
* vi bin/kafka-console-consumer.sh,也就是添加KAFKA_OPTS
```shell
export KAFKA_OPTS="-Djava.security.auth.login.config=/etc/kafka/kafka_client_jaas.conf"
exec $(dirname $0)/kafka-run-class.sh kafka.tools.ConsoleConsumer "$@"
```
* 修改消费者配置文件，最后一行追加2行内容
```shell
 security.protocol=SASL_PLAINTEXT (or SASL_SSL)
 sasl.mechanism=PLAIN (or GSSAPI)
```
## 4.SpringBoot Kafka 配置
```yaml
spring:
  kafka:    
    properties:
      #也可以在producer和consumer的properties中配置
      sasl.mechanism: PLAIN
      #也可以在producer和consumer的properties中配置
      security.protocol: SASL_SSL
      #也可以在producer和consumer的properties中配置
      sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="testuser1" password="123456";
     producer: 
      properties: 
      # 指定生产者采用SASL协议
       security:
        #SASL_PLAINTEXT (or SASL_SSL)
        protocol: SASL_SSL
     consumer: 
      properties: 
       # 指定消费者采用SASL协议
       security:
        #SASL_PLAINTEXT (or SASL_SSL)
        protocol: SASL_SSL
```
## 5.SpringCloudStream 配置
```yaml
spring:
  cloud:
    stream:
      binders:
        kafka:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      brokers: test01:9093,test02:9093,test03:9093
                      configuration:
                        security:
                          protocol: SASL_SSL
                        sasl:
                          mechanism: PLAIN
                          jaas:
                            config: org.apache.kafka.common.security.plain.PlainLoginModule required username="testuser1" password="123456";
                          client:
                            auth: required
```
# 三、使用ACL配置用户操作权限
在所有其他CLI的bin目录下，可以找到Kafka授权管理CLI。CLI脚本称为kafka-acls.sh。以下列出了脚本支持的所有选项见官网：  
http://kafka.apache.org/26/documentation.html#security_authz
## 3.1 添加ACL
### 3.1.1  给指定用户的指定IP授予指定topic的读写权限
假设您要添加acl“允许Principals User：Bob和User：Alice对IP 198.51.100.0和IP 198.51.100.1执行对主题Test-Topic的操作读写”。您可以通过使用以下选项执行CLI来实现：
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic
```
### 3.1.2  让topic拒绝指定用户和指定ip的访问权限
如果我们要允许所有用户从Test-topic读取，而仅拒绝IP 198.51.100.3中的User：BadBob，则可以使用以下命令进行操作：  
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:* --allow-host * --deny-principal User:BadBob --deny-host 198.51.100.3 --operation Read --topic Test-topic
```
请注意，--allow-host并且--deny-host仅支持IP地址（不支持主机名）。  
### 3.1.3  给指定用户的指定IP授予所有topic的写权限
上面的示例通过将--topic [topic-name]指定为资源模式选项来向主题添加ACL。同样，用户可以通过指定--cluster将acls添加到集群，并通过指定--group [group-name]将其添加到使用者组。您可以在特定类型的任何资源上添加ACL  
例如，假设您要添加ACL“允许主用户：Peter可以从IP 198.51.200.0这个ip的客户端向kafka任何主题中写入数据”，您可以使用通配符资源“ *”来实现，通过使用以下选项执行CLI：
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Peter --allow-host 198.51.200.1 --producer --topic *
```
### 3.1.4  给指定用户的指定IP授予所有以XXX为前缀命令的topic的写权限
您可以在带前缀的资源模式上添加ACL，例如，假设您要添加ACL“允许主体用户：Jane到名称从任何主机以'Test-'开头的任何主题”。您可以通过使用以下选项执行CLI来实现： 
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Jane --producer --topic Test- --resource-pattern-type prefixed
```
请注意，--resource-pattern-type默认为'literal'，这只会影响名称完全相同的资源，或者对于通配符资源名称为*的资源，将影响任何名称的资源。
### 3.1.5  给指定用户配置指定topic的写权限(最常用)
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --producer --topic Test-topic
```
### 3.1.6  给指定用户配置指定topic使用指定groupid的读权限(最常用)
```jshelllanguage
 bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --consumer --topic Test-topic --group Group-1
```
## 3.2 删除ACL
删除ACL几乎相同。唯一的区别是用户必须指定--remove选项而不是--add选项。要删除上面第一个示例添加的acl，我们可以使用以下选项执行CLI：
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --remove --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic 
```
如果要删除添加到上述前缀资源模式中的acl，我们可以使用以下选项执行CLI：
```jshelllanguage
 bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --remove --allow-principal User:Jane --producer --topic Test- --resource-pattern-type Prefixed
```
## 3.3 列出ACL
我们可以通过为资源指定--list选项来列出任何资源的ACL。要列出文字资源模式Test-topic上的所有ACL，我们可以使用以下选项执行CLI：
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic Test-topic
```
查看所有topic的ACL权限
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic *
```
但是，*不一定可以在与Test-topic匹配的前缀资源模式上显式查询acl，因为这种模式的名称可能未知。我们可以使用'--resource-pattern-type match' 列出所有影响Test-topic的ACL,这将列出所有匹配的文字，通配符和前缀资源模式的ACL。
```jshelllanguage
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic Test-topic --resource-pattern-type match
```
## 3.4 基于Admin API的ACL管理
详情见官网  
对ClusterResource具有“更改”权限的用户可以使用Admin API进行ACL管理。kafka-acls.sh脚本支持AdminClient API来管理ACL，而无需直接与zookeeper / authorizer进行交互。可以使用--bootstrap-server选项执行以上所有示例。例如：
```jshelllanguage
  bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config /tmp/adminclient-configs.conf --add --allow-principal User:Bob --producer --topic Test-topic
  bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config /tmp/adminclient-configs.conf --add --allow-principal User:Bob --consumer --topic Test-topic --group Group-1
  bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config /tmp/adminclient-configs.conf --list --topic Test-topic
```
参数：
* zookeeper.connect：zk的IP和端口
* --allow-principal：在这里配置设置权限的帐号【User:用户名】，例子中的用户为Bob，可以设置多个
* --allow-host：设置用户允许访问kafka的ip，可以设置多个
* --topic：指定授权的topic
* --deny-principal: 拒绝用户
* --deny-host：拒绝ip
* --resource-pattern-type prefixed：资源匹配使用前缀方式
* --producer：添加/删除生产者角色的ACL的便利选项。这将生成允许对主题进行写入、描述和创建的ACL。
* --consumer：为使用者角色添加/删除ACL的便利选项。这将生成允许读取、主题描述和使用者组读取的ACL。
* --group：限制用户允许使用的groupid
* --operation：权限相关参数，可以设置多个，支持：
Read  
Write
Create  
Delete  
Alter   
Describe  
ClusterAction 
DescribeConfigs 
AlterConfigs
IdempotentWrite
All  
这些操作对应的api见官网：http://kafka.apache.org/26/documentation.html#operations_in_kafka  
* 注意，由于kafka配置sasl认证，而kafka-acls是通过zk访问kafka做权限控制，需要配置zk的jaas，的启动文件也需要配置
先来看一下，默认的bin/kafka-acls.sh的最后一行
```
exec $(dirname $0)/kafka-run-class.sh kafka.admin.AclCommand "$@"
```
只需要在最后一行的上面一行，添加一个环境变量即可
```
export SERVER_JVMFLAGS=" -Djava.security.auth.login.config=/data/kafka-conf/kafka_zk_jaas.conf"
exec $(dirname $0)/kafka-run-class.sh kafka.admin.AclCommand "$@"
```