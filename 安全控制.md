# kafka安全控制
# 一、使用SSL管理通讯安全
## 1.创建所需ssl证书文件
### 脚本
```shell
#!/bin/bash
#################################
BASE_DIR=/data/kafka-ssl
CERT_OUTPUT_PATH="$BASE_DIR/server_cert"
CLIENT_CERT_OUTPUT_PATH="$BASE_DIR/client_cert"
PASSWORD=123456
KEY_STORE="$CERT_OUTPUT_PATH/kafka.keystore.jks"
CLIENT_KEY_STORE="$CLIENT_CERT_OUTPUT_PATH/client-keystore.jks"
TRUST_STORE="$CERT_OUTPUT_PATH/kafka.truststore.jks"
CLIENT_TRUST_STORE="$CLIENT_CERT_OUTPUT_PATH/client-truststore.jks"
CLUSTER_NAME=test
CERT_AUTH_FILE="$CERT_OUTPUT_PATH/ca.crt"
CLUSTER_CERT_FILE="$CERT_OUTPUT_PATH/${CLUSTER_NAME}-cert"
CLIENT_CLUSTER_CERT_FILE="$CERT_OUTPUT_PATH/${CLUSTER_NAME}-cert-client"
DAYS_VALID=999
DNAME="CN=test,OU=test,O=test,L=test,ST=test,C=CN"
#################################
mkdir -p $CERT_OUTPUT_PATH
mkdir -p $CLIENT_CERT_OUTPUT_PATH

echo "1:创建服务端秘钥和证书"
keytool -keystore $KEY_STORE -alias $CLUSTER_NAME -validity $DAYS_VALID -genkey -keyalg RSA \
-storepass $PASSWORD -keypass $PASSWORD -dname "$DNAME"

echo "2:创建客户端秘钥和证书"
keytool -keystore $CLIENT_KEY_STORE -alias $CLUSTER_NAME -validity $DAYS_VALID -genkey -keyalg RSA \
-storepass $PASSWORD -keypass $PASSWORD -dname "$DNAME"

echo "3:创建CA证书"
openssl req -new -x509 -keyout $CERT_OUTPUT_PATH/ca.key -out "$CERT_AUTH_FILE" -days "$DAYS_VALID" \
-passin pass:"$PASSWORD" -passout pass:"$PASSWORD" \
-subj "/C=CN/ST=test/L=test/O=test/CN=CN"

echo "4:将CA证书导入到服务器truststore"
keytool -keystore "$TRUST_STORE" -alias CARoot \
-import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "5:将CA证书导入到客户端truststore"
keytool -keystore "$CLIENT_TRUST_STORE" -alias CARoot \
-import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "6.导出服务器证书"
keytool -keystore "$KEY_STORE" -alias "$CLUSTER_NAME" -certreq -file "$CLUSTER_CERT_FILE" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "7.导出客户器证书"
keytool -keystore "$CLIENT_KEY_STORE" -alias "$CLUSTER_NAME" -certreq -file "$CLIENT_CLUSTER_CERT_FILE" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "8.用CA证书给服务器证书签名"
openssl x509 -req -CA "$CERT_AUTH_FILE" -CAkey $CERT_OUTPUT_PATH/ca.key -in "$CLUSTER_CERT_FILE" \
-out "${CLUSTER_CERT_FILE}-signed" \
-days "$DAYS_VALID" -CAcreateserial -passin pass:"$PASSWORD"

echo "8.用CA证书给客户器证书签名"
openssl x509 -req -CA "$CERT_AUTH_FILE" -CAkey $CERT_OUTPUT_PATH/ca.key -in "$CLIENT_CLUSTER_CERT_FILE" \
-out "${CLIENT_CLUSTER_CERT_FILE}-signed" \
-days "$DAYS_VALID" -CAcreateserial -passin pass:"$PASSWORD"
 
echo "9.将CA证书导入服务端keystore"
keytool -keystore "$KEY_STORE" -alias CARoot -import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "10.将CA证书导入客户端keystore"
keytool -keystore "$CLIENT_KEY_STORE" -alias CARoot -import -file "$CERT_AUTH_FILE" -storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "11:将已签名的服务端证书导入服务器keystore"
keytool -keystore "$KEY_STORE" -alias "${CLUSTER_NAME}" -import -file "${CLUSTER_CERT_FILE}-signed" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt

echo "11:将已签名的客户端证书导入服务器keystore"
keytool -keystore "$CLIENT_KEY_STORE" -alias "${CLUSTER_NAME}" -import -file "${CLIENT_CLUSTER_CERT_FILE}-signed" \
-storepass "$PASSWORD" -keypass "$PASSWORD" -noprompt
```
创建的文件清单：
* 服务端文件
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-1.jpg)
* 客户端文件
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-2.jpg)

## 2.服务端配置
### 2.1 配置ssl监听
Kafka Broker支持监听多个端口上的连接，通过server.properteis 配置，最少监听1个端口，用逗号分隔。
```
listeners=PLAINTEXT://host.name:port,SSL://host.name:port
```
* CDH对应配置
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-3.png)
### 2.2 配置ssl文件和密码
```
ssl.keystore.location=/data/kafka-ssl/server_cert/kafka.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/data/kafka-ssl/server_cert/kafka.truststore.jks
ssl.truststore.password=test1234
```
* CDH对应配置
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-4.png)
### 2.2 ssl其他配置
### 2.2.1 ssl.client.auth
* required：客户端身份验证是必需的，客户端必须同时配置keystore和truststore
* node：不启动验证
* requested：客户端身份验证请求，客户端没有证书仍然可以连接，客户端连接Kafka只用配置truststore
* CDH配置：
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-5.png)
### 2.2.2. ssl.enabled.protocols = TLSv1.2 TLSv1.1 TLSv1 
* TLSv1.2 TLSv1.1 TLSv1 ，接收来自客户端列出的SSL协议，注意，不推荐在生产中使用SSL，推荐使用TLS)。
* CDH不能配置具体协议，只能选择是否启动
![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-6.png)
### 2.2.3. security.inter.broker.protocol 
* broker内部通信使用协议，默认和外部通讯协议保持一致，在CDH中需要也配置成SSL，普通kafka根据实际情况配置，一版配置为普通文本模式，不用
 ![](https://github.com/lk6678979/image/blob/master/kafka-ssl/kakfa-ssh-7.jpg)
 ### 2.2.4. 其他
* ssl.keystore.type=JKS
* ssl.truststore.type=JKS
* ssl.secure.random.implementation=SHA1PRNG
* advertised.listeners = SSL://localhost:9095
* advertised.listeners和listeners的区别：
   listeners：就是主要用来定义Kafka Broker的Listener的配置项。
   advertised.listeners：参数的作用就是将Broker的Listener信息发布到Zookeeper中，也就是说通过zk链接kafka里的broker是这个配置的对应监听地址，如果advertised.listeners未配置，会使用listeners的值
### 配置案例
```
listeners=SSL://localhost:9095
advertised.listeners=SSL://localhost:9095
ssl.keystore.location=/Users/smartloli/workspace/ssl/certificates/kafka.keystore
ssl.keystore.password=ke123456
ssl.key.password=ke123456
ssl.truststore.location=/Users/dengjie/workspace/ssl/certificates/kafka.truststore
ssl.truststore.password=ke123456

ssl.client.auth=required
ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1
ssl.keystore.type=JKS 
ssl.truststore.type=JKS 
ssl.endpoint.identification.algorithm=HTTPS
security.inter.broker.protocol=SSL
```
# 二、使用SASL+ACL对用户进行权限控制(不使用Kerberos)
注意：CDH只支持Kerberos，否则启动kafka会直接提示
```
security.inter.broker.protocol can not be set to SASL_SSL, as Kerberos is not enabled on this Kafka broker.
```
## 2.1 配置SASL
* 1.在broker中选择1个或多个支持的机制启用，kafka目前支持的机制有 GSSAPI 和 PLAIN 。  
* 2.在server.properties配置一个SASL端口，增加至少1个SASL_PLAINTEXT或SASL_SSL到listeners。用逗号分隔：
```
 listeners=SASL_PLAINTEXT://host.name:port
```
如果使用SASL_SSL，那SSL也必须配置，如果你仅配置SASL端口（或者，如果你需要broker互相使用SASL进行身份验证），那么，确保你设置相同的SASL协议为broker间通讯:
```
security.inter.broker.protocol=SASL_PLAINTEXT (or SASL_SSL)
```
* 3.在server.properties中启用1个或多个SASL机制:
```
sasl.enabled.mechanisms=GSSAPI (,PLAIN)
```
注意这里配置PLAIN,如果配置GSSAPI则需要安装Kerberos
* 4.如果使用SASL做broker之间通信，在server.properties中配置SASL机制：
```
sasl.mechanism.inter.broker.protocol=GSSAPI (or PLAIN)
```
注意这里配置PLAIN,如果配置GSSAPI则需要安装Kerberos
* 5.allow.everyone.if.no.acl.found=ture
该配置的意思是：如果用户没有配置任何acl权限，能否访问数据，默认是false，也就是除了超级用户之外，其他用户无法访问。  
那么问题就来了，在kafka集群中，其它节点需要同步数据，需要相互访问。节点之间是默认会使用ANONYMOUS的用户名连接集群。在这种情况下，启动kafka集群，必然失败！所以必须设置为true，然后给非超级用户严格控制访问权限
```
org.apache.kafka.common.errors.ClusterAuthorizationException: Request Request(processor=0, connectionId=10.88.25.65:9092-10.88.25.65:49446-0, session=Session(User:ANONYMOUS,/10.88.25.65), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=null) is not authorized.
```

* 6.配置实例：
```
# 配置ACL入口类
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
advertised.listeners=SASL_PLAINTEXT://$advertised_hostname:9092
# 本例使用SASL_PLAINTEXT
listeners=SASL_PLAINTEXT://:9092
security.inter.broker.protocol= SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN
allow.everyone.if.no.acl.found=true
# 设置本例中admin为超级用户
super.users=User:admin
```
## 2.1 启动服务端
### 2.1.1 添加一个JAAS文件来配置选择的 GSSAPI（Kerberos）或 PLANIN。  
本例中，我们假设有3个用户：admin, reader和writer，其中admin是管理员，reader用户读取Kafka集群中topic数据，而writer用户则负责向Kafka集群写入消息,存放目录：/data/kafka-conf/kafka_cluster_jaas.conf
```
KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="admin"
  password="123456"
  user_admin="123456"
  user_test="test123456";
};

```
这个文件，是专门用来做认证的。用户名和密码的格式如下：user_用户名="密码"  
注意：对于超级用户，这几行是固定的,这里指定的是admin用户密码为123456，密码可自行更改
```
username="admin"
password="123456"
user_admin="admin"
```
### 2.1.2 启动
bin/kafka-server-start.sh 这个是kafka的启动脚本，要使用ACL，需要增加一个参数才行
有2种方法修改，这里分别介绍一下：
* 增加环境变量KAFKA_OPTS(推荐)
先来看一下，默认的bin/kafka-server-start.sh的最后一行
```
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```
只需要在最后一行的上面一行，添加一个环境变量即可
```
export KAFKA_OPTS="-Djava.security.auth.login.config=/data/kafka-conf/kafka_cluster_jaas.conf"
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```
* 增加参数-Djava.security.auth.login.config
直接将最后一行修改为
```
exec $base_dir/kafka-run-class.sh -Djava.security.auth.login.config=/data/kafka-conf/kafka_cluster_jaas.conf $EXTRA_ARGS kafka.Kafka "$@"
```
